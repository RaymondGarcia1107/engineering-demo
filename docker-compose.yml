services: 

  airflow-init:
    image: apache/airflow:2.7.2
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    volumes:
      - ./airflow/dags:/opt/airflow/dags   
    entrypoint: >
      bash -c "
        airflow db upgrade &&
        airflow users list | grep -q admin || airflow users create --username admin --password admin --firstname Ray --lastname Garcia --role Admin --email raygarcia@alteradata.com
      "

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    image: apache/airflow:2.7.2
    restart: always
    depends_on:
      - airflow-init
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      PYTHONPATH: /opt/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - ./etl:/opt/airflow/etl
    ports:
      - "8080:8080"
    command: airflow webserver

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    image: apache/airflow:2.7.2
    depends_on:
      - airflow-webserver
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      PYTHONPATH: /opt/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - ./etl:/opt/airflow/etl
    command: airflow scheduler

  dbt:
    image: ghcr.io/dbt-labs/dbt-postgres:1.7.8
    working_dir: /opt/dbt
    volumes:
      - ./dbt:/opt/dbt
    entrypoint: ["tail", "-f", "/dev/null"]  # Keeps it running for shell access
    env_file:
      - .env
    environment:
      DBT_PROFILES_DIR: /opt/dbt